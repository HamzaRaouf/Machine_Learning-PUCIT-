{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkf8-XmA72YS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDFnrSNj-0u6"
      },
      "outputs": [],
      "source": [
        "#specify path of the dataset folder\n",
        "#path = \"/content/sample_data/activity_monitoring/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aqp09hRM_Adh"
      },
      "outputs": [],
      "source": [
        "#train_msAcc = load(train_MSAccelerometer_OpenDoor_RubHands.npy)\n",
        "#train_msGyro = load(train_MSGyroscope_OpenDoor_RubHands.npy)\n",
        "#train_labels = load(train_labels_OpenDoor_RubHands.npy)\n",
        "\n",
        "#test_msAcc = load(test_MSAccelerometer_OpenDoor_RubHands.npy)\n",
        "#test_msGyro = load(test_MSGyroscope_OpenDoor_RubHands.npy)\n",
        "#test_labels = load(test_labels_OpenDoor_RubHands.npy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hby7Yux2AwMP"
      },
      "outputs": [],
      "source": [
        "#print the shapes of all data arrays\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0Kwt5mzDxLx"
      },
      "outputs": [],
      "source": [
        "#set number of train examples and test examples according to the shape of train and test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnCrWpy3EmxB"
      },
      "outputs": [],
      "source": [
        "#decide for num of features for example min, max, mean, std, etc. and create/prepare numpy arrays (for training and testing data) to store them\n",
        "#Hint: size of train_features array = np.zeros((train_num_examples, num_of_sensors * num_features, 3))\n",
        "\n",
        "# print/verify their shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kj1LZGxgISbx"
      },
      "outputs": [],
      "source": [
        "#feaure extraction (mean, max, min, std, etc)\n",
        "# generation of features for training data set\n",
        "train_features[:,0,:] = np.mean(train_msAcc, axis=1)\n",
        "#continue for all train features\n",
        "\n",
        "train_features[:,4,:] = np.mean(train_msGyro, axis=1)\n",
        "#continue for all train features\n",
        "\n",
        "\n",
        "# generation of features for testing data set\n",
        "test_features[:,0,:] = np.mean(test_msAcc, axis=1)\n",
        "#continue for all test features\n",
        "\n",
        "test_features[:,4,:] = np.mean(test_msGyro, axis=1)\n",
        "#continue for all test features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eN50h7NQKsd5"
      },
      "outputs": [],
      "source": [
        "#reshape and combine all features\n",
        "#print(np.shape(train_features))\n",
        "#train_features_reshaped = np.reshape(train_features, (np.shape(train_features)[0], np.shape(train_features)[1]*np.shape(train_features)[2] ))\n",
        "#print(np.shape(train_features_reshaped))\n",
        "\n",
        "\n",
        "#print(np.shape(test_features))\n",
        "#test_features_reshaped = np.reshape(test_features, (np.shape(test_features)[0], np.shape(test_features)[1]*np.shape(test_features)[2] ))\n",
        "#print(np.shape(test_features_reshaped))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAkVG-FbL7Co"
      },
      "outputs": [],
      "source": [
        "#You should use ML classification algorithms, for example SVM, logistic regression, decision trees, random forest etc,\n",
        "#The following example uses SVM. You should search for the library functions for other classifiers and use them.\n",
        "classfier = SVC(C=1.0, kernel='linear')  # non-linear kernel is proposed by the fernando's paper\n",
        "classfier.fit(train_features_reshaped,train_labels)\n",
        "estimatedLabels = classfier.predict(test_features_reshaped)\n",
        "\n",
        "accuracy = accuracy_score(test_labels,estimatedLabels)\n",
        "weightedF1 = f1_score(test_labels,estimatedLabels,average='weighted')\n",
        "averageF1 = f1_score(test_labels,estimatedLabels,average='macro')\n",
        "allF1Scores = f1_score(test_labels,estimatedLabels,average=None)\n",
        "conf_matrix = confusion_matrix(test_labels,estimatedLabels)\n",
        "\n",
        "# Print results\n",
        "print('   C = 1.0 ')\n",
        "print('   Average F1-score = %.4f' % (averageF1))\n",
        "print('   Test accuracy = %.2f %%' % (accuracy*100))\n",
        "print('   Weighted F1-score = %.4f' % (weightedF1))\n",
        "print('   All F1-scores:')\n",
        "print(allF1Scores)\n",
        "print('   Confusion Matrix:')\n",
        "print(conf_matrix)\n",
        "\n",
        "print('-------------------------------------------------------')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HhZ4a74U4An"
      },
      "outputs": [],
      "source": [
        "#For this assignment you should Create a neural network for binary classification.\n",
        "\n",
        "#The following information is just for example\n",
        "# batchSize = 50\n",
        "# learningRate = 0.5 , you may also test 1, 0.5, 0.1, 0.01 and provide comparison\n",
        "# epochs = 150\n",
        "# targetDataProportion = 1\n",
        "\n",
        "# msbandModel = {\n",
        "#     'name': 'CNN',\n",
        "#     'nb_conv_blocks' : 3,\n",
        "#     'nb_conv_kernels' : [10,10,10],\n",
        "#     'conv_kernels_size' : [(9,),(11,),(11,)],\n",
        "#     'pooling_size' : [(2,),(2,),(2,)],\n",
        "#     'activation' : 'relu',\n",
        "#     }\n",
        "# linear or dense layer Size = [2000,2000,2000]... but its too much. Go for smaller number of nodes.\n",
        "# denseActivation = 'relu'\n",
        "\n",
        "\n",
        "\n",
        "# trainingMSAcc = torch.from_numpy(train_msAcc)\n",
        "# trainingMSGyro = torch.from_numpy(train_msGyro)\n",
        "# trainingLabels = torch.from_numpy(train_labels)\n",
        "\n",
        "# testingMSAcc = torch.from_numpy(test_msAcc)\n",
        "# testingMSGyro = torch.from_numpy(test_msGyro)\n",
        "# testingLabels = torch.from_numpy(test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfBSpbLcFOWx"
      },
      "outputs": [],
      "source": [
        "# #feaure extraction (mean, max, min, std)\n",
        "# m = np.mean(train_msAcc, axis=1)\n",
        "# print(np.mean(train_msAcc[0,:,0]))\n",
        "# print(np.mean(train_msAcc[0,:,1]))\n",
        "# print(np.mean(train_msAcc[0,:,2]))\n",
        "# print(m[0])\n",
        "# print(m[1])\n",
        "# print(m.shape)\n",
        "# m = m.flatten()\n",
        "# print(m.shape)\n",
        "# print(m[0])\n",
        "# print(m[1])\n",
        "# print(m[2])\n",
        "# print(m[3])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}